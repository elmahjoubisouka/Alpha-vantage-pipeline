"""
DAG: collect_and_store_dag - VERSION COMPLÃˆTE AVEC CRÃ‰ATION TABLES
Ã‰quipe: Assia Boujnah, Soukaina El Mahjoubi, Khalil Fatima
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)

default_args = {
    'owner': 'equipe_finance',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

SYMBOLS = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX']

def create_tables_snowflake(**context):
    """CRÃ‰E les tables dans Snowflake si elles n'existent pas"""
    logger.info("ğŸ—ï¸  CrÃ©ation des tables dans Snowflake...")
    
    try:
        hook = SnowflakeHook(snowflake_conn_id='snowflake_default')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # 1. VÃ©rifier et crÃ©er la database si nÃ©cessaire
        cursor.execute("CREATE DATABASE IF NOT EXISTS FINANCE_DB")
        cursor.execute("USE DATABASE FINANCE_DB")
        cursor.execute("CREATE SCHEMA IF NOT EXISTS STOCK_DATA")
        cursor.execute("USE SCHEMA STOCK_DATA")
        cursor.execute("USE WAREHOUSE COMPUTE_WH")
        
        logger.info("âœ… Contexte Snowflake configurÃ©")
        
        # 2. CrÃ©er la table pour donnÃ©es brutes
        create_raw_table = """
        CREATE TABLE IF NOT EXISTS RAW_STOCK_DATA (
            date TIMESTAMP_NTZ NOT NULL,
            symbol VARCHAR(10),
            open NUMBER(20, 4),
            high NUMBER(20, 4),
            low NUMBER(20, 4),
            close NUMBER(20, 4),
            volume NUMBER(38, 0),
            dividends NUMBER(20, 4),
            stock_splits NUMBER(20, 4),
            extraction_date TIMESTAMP_NTZ,
            PRIMARY KEY (symbol, date)
        )
        """
        
        cursor.execute(create_raw_table)
        logger.info("âœ… Table RAW_STOCK_DATA crÃ©Ã©e/vÃ©rifiÃ©e")
        
        # 3. CrÃ©er la table pour donnÃ©es traitÃ©es (pour plus tard)
        create_processed_table = """
        CREATE TABLE IF NOT EXISTS PROCESSED_STOCK_DATA (
            date TIMESTAMP_NTZ NOT NULL,
            symbol VARCHAR(10),
            open NUMBER(20, 4),
            high NUMBER(20, 4),
            low NUMBER(20, 4),
            close NUMBER(20, 4),
            volume NUMBER(38, 0),
            rsi NUMBER(10, 4),
            macd NUMBER(20, 4),
            macd_signal NUMBER(20, 4),
            macd_diff NUMBER(20, 4),
            ma_20 NUMBER(20, 4),
            ma_50 NUMBER(20, 4),
            bb_high NUMBER(20, 4),
            bb_low NUMBER(20, 4),
            bb_mid NUMBER(20, 4),
            adx NUMBER(10, 4),
            atr NUMBER(20, 4),
            volume_sma NUMBER(20, 4),
            processing_date TIMESTAMP_NTZ,
            PRIMARY KEY (symbol, date)
        )
        """
        
        cursor.execute(create_processed_table)
        logger.info("âœ… Table PROCESSED_STOCK_DATA crÃ©Ã©e/vÃ©rifiÃ©e")
        
        # 4. VÃ©rifier les tables crÃ©Ã©es
        cursor.execute("SHOW TABLES")
        tables = cursor.fetchall()
        
        logger.info("ğŸ“‹ Tables disponibles:")
        for table in tables:
            logger.info(f"   - {table[1]}")
        
        # 5. Nettoyer les anciennes donnÃ©es (optionnel, pour dÃ©mo)
        cursor.execute("DELETE FROM RAW_STOCK_DATA")
        cursor.execute("DELETE FROM PROCESSED_STOCK_DATA")
        logger.info("ğŸ§¹ Tables nettoyÃ©es (prÃªtes pour nouvelles donnÃ©es)")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        logger.info("ğŸ‰ Tables Snowflake prÃªtes !")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erreur crÃ©ation tables: {str(e)[:200]}")
        raise

def create_demo_data(**context):
    """CrÃ©e des donnÃ©es de dÃ©monstration"""
    logger.info("ğŸ“ CrÃ©ation de donnÃ©es de dÃ©monstration...")
    
    all_data = []
    extraction_date = datetime.now()
    
    # Configuration rÃ©aliste
    demo_config = {
        'AAPL': {'base': 185.0, 'vol': 0.025},
        'MSFT': {'base': 370.0, 'vol': 0.020},
        'GOOGL': {'base': 140.0, 'vol': 0.030},
        'AMZN': {'base': 150.0, 'vol': 0.028},
        'TSLA': {'base': 240.0, 'vol': 0.050},
        'NVDA': {'base': 500.0, 'vol': 0.040},
        'META': {'base': 350.0, 'vol': 0.035},
        'NFLX': {'base': 490.0, 'vol': 0.032}
    }
    
    for symbol in SYMBOLS:
        config = demo_config.get(symbol, {'base': 200.0, 'vol': 0.03})
        base_price = config['base']
        
        # GÃ©nÃ©rer 60 jours de donnÃ©es
        dates = pd.date_range(end=extraction_date.date(), periods=60, freq='B')
        
        np.random.seed(hash(symbol) % 10000)
        trend = np.linspace(0.95, 1.05, 60)
        noise = 1 + np.random.randn(60) * config['vol']
        close_prices = base_price * trend * noise
        
        for i, date in enumerate(dates):
            all_data.append({
                'date': date.strftime('%Y-%m-%d %H:%M:%S'),
                'symbol': symbol,
                'open': float(close_prices[i] * (1 - np.random.uniform(0, 0.01))),
                'high': float(close_prices[i] * (1 + np.random.uniform(0, 0.02))),
                'low': float(close_prices[i] * (1 - np.random.uniform(0, 0.02))),
                'close': float(close_prices[i]),
                'volume': int(np.random.randint(5_000_000, 50_000_000)),
                'dividends': float(np.random.choice([0, 0.23], p=[0.98, 0.02])),
                'stock_splits': 0.0,
                'extraction_date': extraction_date.strftime('%Y-%m-%d %H:%M:%S')
            })
    
    logger.info(f"ğŸ“Š {len(all_data)} lignes crÃ©Ã©es pour {len(SYMBOLS)} symboles")
    
    # Stocker dans XCom
    context['ti'].xcom_push(key='raw_data', value=all_data)
    return all_data

def save_to_snowflake_raw(**context):
    """Sauvegarde dans Snowflake - VERSION SIMPLIFIÃ‰E"""
    ti = context['ti']
    raw_data = ti.xcom_pull(task_ids='create_demo_data', key='raw_data')
    
    if not raw_data:
        logger.error("âŒ Aucune donnÃ©e Ã  sauvegarder")
        return 0
    
    logger.info(f"ğŸ’¾ Sauvegarde de {len(raw_data)} lignes dans Snowflake...")
    
    try:
        hook = SnowflakeHook(snowflake_conn_id='snowflake_default')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # Configurer le contexte
        cursor.execute("USE DATABASE FINANCE_DB")
        cursor.execute("USE SCHEMA STOCK_DATA")
        cursor.execute("USE WAREHOUSE COMPUTE_WH")
        
        # PrÃ©parer la requÃªte d'insertion
        insert_query = """
            INSERT INTO RAW_STOCK_DATA 
            (date, symbol, open, high, low, close, volume, dividends, stock_splits, extraction_date)
            VALUES (TO_TIMESTAMP(%s, 'YYYY-MM-DD HH24:MI:SS'), %s, %s, %s, %s, %s, %s, %s, %s, 
                    TO_TIMESTAMP(%s, 'YYYY-MM-DD HH24:MI:SS'))
        """
        
        # InsÃ©rer par batch
        batch_size = 50
        inserted = 0
        
        for i in range(0, len(raw_data), batch_size):
            batch = raw_data[i:i+batch_size]
            values = []
            
            for row in batch:
                values.append((
                    row['date'],
                    row['symbol'],
                    row['open'],
                    row['high'],
                    row['low'],
                    row['close'],
                    row['volume'],
                    row['dividends'],
                    row['stock_splits'],
                    row['extraction_date']
                ))
            
            cursor.executemany(insert_query, values)
            inserted += len(batch)
            if i % 200 == 0:
                logger.info(f"ğŸ“¤ {inserted} lignes insÃ©rÃ©es...")
        
        conn.commit()
        
        # VÃ©rification
        cursor.execute("SELECT COUNT(*) FROM RAW_STOCK_DATA")
        total = cursor.fetchone()[0]
        
        logger.info(f"âœ… {inserted} lignes sauvegardÃ©es")
        logger.info(f"ğŸ“Š Total en base: {total} lignes")
        
        # Afficher un rÃ©sumÃ©
        cursor.execute("""
            SELECT symbol, COUNT(*), AVG(close) 
            FROM RAW_STOCK_DATA 
            GROUP BY symbol
        """)
        
        logger.info("ğŸ“‹ RÃ©sumÃ© par symbole:")
        for symbol, count, avg_price in cursor.fetchall():
            logger.info(f"   {symbol}: {count} jours, prix moyen=${avg_price:.2f}")
        
        cursor.close()
        conn.close()
        
        return inserted
        
    except Exception as e:
        logger.error(f"âŒ Erreur sauvegarde: {str(e)[:200]}")
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()
        raise

def quality_check_raw(**context):
    """VÃ©rifie la qualitÃ© des donnÃ©es brutes"""
    logger.info("ğŸ” ContrÃ´le qualitÃ© donnÃ©es brutes...")
    
    try:
        hook = SnowflakeHook(snowflake_conn_id='snowflake_default')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        cursor.execute("USE DATABASE FINANCE_DB")
        cursor.execute("USE SCHEMA STOCK_DATA")
        
        # VÃ©rifications de base
        checks = [
            ("Nombre total de lignes", "SELECT COUNT(*) FROM RAW_STOCK_DATA"),
            ("Nombre de symboles", "SELECT COUNT(DISTINCT symbol) FROM RAW_STOCK_DATA"),
            ("PÃ©riode couverte", "SELECT MIN(date), MAX(date) FROM RAW_STOCK_DATA"),
            ("Valeurs nulles", "SELECT COUNT(*) FROM RAW_STOCK_DATA WHERE close IS NULL"),
            ("Volume moyen", "SELECT AVG(volume) FROM RAW_STOCK_DATA")
        ]
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š QUALITÃ‰ DES DONNÃ‰ES BRUTES")
        logger.info("=" * 60)
        
        for check_name, query in checks:
            cursor.execute(query)
            result = cursor.fetchone()
            logger.info(f"âœ“ {check_name}: {result[0]}")
        
        # DÃ©tail par symbole
        cursor.execute("""
            SELECT symbol, 
                   COUNT(*) as jours,
                   AVG(close) as prix_moyen,
                   MIN(close) as prix_min,
                   MAX(close) as prix_max
            FROM RAW_STOCK_DATA
            GROUP BY symbol
            ORDER BY symbol
        """)
        
        logger.info("\nğŸ“ˆ DÃ©tail par symbole:")
        for row in cursor.fetchall():
            logger.info(f"   {row[0]}: {row[1]} jours, prix ${row[2]:.2f} (min:${row[3]:.2f}, max:${row[4]:.2f})")
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ COLLECTE TERMINÃ‰E AVEC SUCCÃˆS!")
        logger.info("=" * 60)
        
        cursor.close()
        conn.close()
        
        return True
        
    except Exception as e:
        logger.error(f"âš ï¸ Erreur contrÃ´le qualitÃ©: {e}")
        return True

# Configuration du DAG
with DAG(
    'collect_and_store_dag_v2',
    default_args=default_args,
    description='Collecte complÃ¨te avec crÃ©ation automatique des tables',
    schedule_interval='0 8 * * 1-5',
    catchup=False,
    tags=['finance', 'snowflake', 'collect', 'automated'],
) as dag:
    
    # NOUVELLE TÃ‚CHE: CrÃ©ation des tables
    create_tables = PythonOperator(
        task_id='create_tables_snowflake',
        python_callable=create_tables_snowflake,
    )
    
    create_data = PythonOperator(
        task_id='create_demo_data',
        python_callable=create_demo_data,
    )
    
    save_data = PythonOperator(
        task_id='save_to_snowflake_raw',
        python_callable=save_to_snowflake_raw,
    )
    
    quality_check = PythonOperator(
        task_id='quality_check_raw',
        python_callable=quality_check_raw,
    )
    
    # Nouveau workflow: crÃ©er tables â†’ crÃ©er donnÃ©es â†’ sauvegarder â†’ vÃ©rifier
    create_tables >> create_data >> save_data >> quality_check

# Documentation
dag.doc_md = """
## DAG de Collecte - Version ComplÃ¨te

**Ã‰quipe:** Assia Boujnah, Soukaina El Mahjoubi, Khalil Fatima

### ğŸ¯ Objectif
Pipeline complet de collecte avec crÃ©ation automatique des tables Snowflake.

### ğŸ”„ Nouveau Workflow
1. **CrÃ©er tables Snowflake** â†’ CrÃ©e les tables si elles n'existent pas
2. **CrÃ©er donnÃ©es dÃ©mo** â†’ GÃ©nÃ¨re 480 lignes de donnÃ©es financiÃ¨res
3. **Sauvegarder dans Snowflake** â†’ InsÃ¨re dans `RAW_STOCK_DATA`
4. **ContrÃ´le qualitÃ©** â†’ VÃ©rifie l'intÃ©gritÃ©

### ğŸ“Š DonnÃ©es gÃ©nÃ©rÃ©es
- 8 symboles boursiers
- 60 jours historiques par symbole
- Prix: open, high, low, close
- Volume, dividends, stock_splits

### âœ… Avantages
- **Robuste**: CrÃ©e automatiquement les tables
- **Idempotent**: Peut Ãªtre relancÃ© sans erreur
- **VÃ©rifiÃ©**: ContrÃ´le qualitÃ© intÃ©grÃ©
"""